{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "import os\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 让torch判断是否使用GPU，建议使用GPU环境，因为会快很多\n",
    "#DEVICE = torch.device(\"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)#加载预训练的模型，也可以不加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)#查看renet50的网络结构，如果不修改网络结构来训练自己的模型的话，只需要修改全连接层的输入和输出即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1.weight\n",
      "1 bn1.weight\n",
      "2 bn1.bias\n",
      "3 bn1.running_mean\n",
      "4 bn1.running_var\n",
      "5 bn1.num_batches_tracked\n",
      "6 layer1.0.conv1.weight\n",
      "7 layer1.0.bn1.weight\n",
      "8 layer1.0.bn1.bias\n",
      "9 layer1.0.bn1.running_mean\n",
      "10 layer1.0.bn1.running_var\n",
      "11 layer1.0.bn1.num_batches_tracked\n",
      "12 layer1.0.conv2.weight\n",
      "13 layer1.0.bn2.weight\n",
      "14 layer1.0.bn2.bias\n",
      "15 layer1.0.bn2.running_mean\n",
      "16 layer1.0.bn2.running_var\n",
      "17 layer1.0.bn2.num_batches_tracked\n",
      "18 layer1.0.conv3.weight\n",
      "19 layer1.0.bn3.weight\n",
      "20 layer1.0.bn3.bias\n",
      "21 layer1.0.bn3.running_mean\n",
      "22 layer1.0.bn3.running_var\n",
      "23 layer1.0.bn3.num_batches_tracked\n",
      "24 layer1.0.downsample.0.weight\n",
      "25 layer1.0.downsample.1.weight\n",
      "26 layer1.0.downsample.1.bias\n",
      "27 layer1.0.downsample.1.running_mean\n",
      "28 layer1.0.downsample.1.running_var\n",
      "29 layer1.0.downsample.1.num_batches_tracked\n",
      "30 layer1.1.conv1.weight\n",
      "31 layer1.1.bn1.weight\n",
      "32 layer1.1.bn1.bias\n",
      "33 layer1.1.bn1.running_mean\n",
      "34 layer1.1.bn1.running_var\n",
      "35 layer1.1.bn1.num_batches_tracked\n",
      "36 layer1.1.conv2.weight\n",
      "37 layer1.1.bn2.weight\n",
      "38 layer1.1.bn2.bias\n",
      "39 layer1.1.bn2.running_mean\n",
      "40 layer1.1.bn2.running_var\n",
      "41 layer1.1.bn2.num_batches_tracked\n",
      "42 layer1.1.conv3.weight\n",
      "43 layer1.1.bn3.weight\n",
      "44 layer1.1.bn3.bias\n",
      "45 layer1.1.bn3.running_mean\n",
      "46 layer1.1.bn3.running_var\n",
      "47 layer1.1.bn3.num_batches_tracked\n",
      "48 layer1.2.conv1.weight\n",
      "49 layer1.2.bn1.weight\n",
      "50 layer1.2.bn1.bias\n",
      "51 layer1.2.bn1.running_mean\n",
      "52 layer1.2.bn1.running_var\n",
      "53 layer1.2.bn1.num_batches_tracked\n",
      "54 layer1.2.conv2.weight\n",
      "55 layer1.2.bn2.weight\n",
      "56 layer1.2.bn2.bias\n",
      "57 layer1.2.bn2.running_mean\n",
      "58 layer1.2.bn2.running_var\n",
      "59 layer1.2.bn2.num_batches_tracked\n",
      "60 layer1.2.conv3.weight\n",
      "61 layer1.2.bn3.weight\n",
      "62 layer1.2.bn3.bias\n",
      "63 layer1.2.bn3.running_mean\n",
      "64 layer1.2.bn3.running_var\n",
      "65 layer1.2.bn3.num_batches_tracked\n",
      "66 layer2.0.conv1.weight\n",
      "67 layer2.0.bn1.weight\n",
      "68 layer2.0.bn1.bias\n",
      "69 layer2.0.bn1.running_mean\n",
      "70 layer2.0.bn1.running_var\n",
      "71 layer2.0.bn1.num_batches_tracked\n",
      "72 layer2.0.conv2.weight\n",
      "73 layer2.0.bn2.weight\n",
      "74 layer2.0.bn2.bias\n",
      "75 layer2.0.bn2.running_mean\n",
      "76 layer2.0.bn2.running_var\n",
      "77 layer2.0.bn2.num_batches_tracked\n",
      "78 layer2.0.conv3.weight\n",
      "79 layer2.0.bn3.weight\n",
      "80 layer2.0.bn3.bias\n",
      "81 layer2.0.bn3.running_mean\n",
      "82 layer2.0.bn3.running_var\n",
      "83 layer2.0.bn3.num_batches_tracked\n",
      "84 layer2.0.downsample.0.weight\n",
      "85 layer2.0.downsample.1.weight\n",
      "86 layer2.0.downsample.1.bias\n",
      "87 layer2.0.downsample.1.running_mean\n",
      "88 layer2.0.downsample.1.running_var\n",
      "89 layer2.0.downsample.1.num_batches_tracked\n",
      "90 layer2.1.conv1.weight\n",
      "91 layer2.1.bn1.weight\n",
      "92 layer2.1.bn1.bias\n",
      "93 layer2.1.bn1.running_mean\n",
      "94 layer2.1.bn1.running_var\n",
      "95 layer2.1.bn1.num_batches_tracked\n",
      "96 layer2.1.conv2.weight\n",
      "97 layer2.1.bn2.weight\n",
      "98 layer2.1.bn2.bias\n",
      "99 layer2.1.bn2.running_mean\n",
      "100 layer2.1.bn2.running_var\n",
      "101 layer2.1.bn2.num_batches_tracked\n",
      "102 layer2.1.conv3.weight\n",
      "103 layer2.1.bn3.weight\n",
      "104 layer2.1.bn3.bias\n",
      "105 layer2.1.bn3.running_mean\n",
      "106 layer2.1.bn3.running_var\n",
      "107 layer2.1.bn3.num_batches_tracked\n",
      "108 layer2.2.conv1.weight\n",
      "109 layer2.2.bn1.weight\n",
      "110 layer2.2.bn1.bias\n",
      "111 layer2.2.bn1.running_mean\n",
      "112 layer2.2.bn1.running_var\n",
      "113 layer2.2.bn1.num_batches_tracked\n",
      "114 layer2.2.conv2.weight\n",
      "115 layer2.2.bn2.weight\n",
      "116 layer2.2.bn2.bias\n",
      "117 layer2.2.bn2.running_mean\n",
      "118 layer2.2.bn2.running_var\n",
      "119 layer2.2.bn2.num_batches_tracked\n",
      "120 layer2.2.conv3.weight\n",
      "121 layer2.2.bn3.weight\n",
      "122 layer2.2.bn3.bias\n",
      "123 layer2.2.bn3.running_mean\n",
      "124 layer2.2.bn3.running_var\n",
      "125 layer2.2.bn3.num_batches_tracked\n",
      "126 layer2.3.conv1.weight\n",
      "127 layer2.3.bn1.weight\n",
      "128 layer2.3.bn1.bias\n",
      "129 layer2.3.bn1.running_mean\n",
      "130 layer2.3.bn1.running_var\n",
      "131 layer2.3.bn1.num_batches_tracked\n",
      "132 layer2.3.conv2.weight\n",
      "133 layer2.3.bn2.weight\n",
      "134 layer2.3.bn2.bias\n",
      "135 layer2.3.bn2.running_mean\n",
      "136 layer2.3.bn2.running_var\n",
      "137 layer2.3.bn2.num_batches_tracked\n",
      "138 layer2.3.conv3.weight\n",
      "139 layer2.3.bn3.weight\n",
      "140 layer2.3.bn3.bias\n",
      "141 layer2.3.bn3.running_mean\n",
      "142 layer2.3.bn3.running_var\n",
      "143 layer2.3.bn3.num_batches_tracked\n",
      "144 layer3.0.conv1.weight\n",
      "145 layer3.0.bn1.weight\n",
      "146 layer3.0.bn1.bias\n",
      "147 layer3.0.bn1.running_mean\n",
      "148 layer3.0.bn1.running_var\n",
      "149 layer3.0.bn1.num_batches_tracked\n",
      "150 layer3.0.conv2.weight\n",
      "151 layer3.0.bn2.weight\n",
      "152 layer3.0.bn2.bias\n",
      "153 layer3.0.bn2.running_mean\n",
      "154 layer3.0.bn2.running_var\n",
      "155 layer3.0.bn2.num_batches_tracked\n",
      "156 layer3.0.conv3.weight\n",
      "157 layer3.0.bn3.weight\n",
      "158 layer3.0.bn3.bias\n",
      "159 layer3.0.bn3.running_mean\n",
      "160 layer3.0.bn3.running_var\n",
      "161 layer3.0.bn3.num_batches_tracked\n",
      "162 layer3.0.downsample.0.weight\n",
      "163 layer3.0.downsample.1.weight\n",
      "164 layer3.0.downsample.1.bias\n",
      "165 layer3.0.downsample.1.running_mean\n",
      "166 layer3.0.downsample.1.running_var\n",
      "167 layer3.0.downsample.1.num_batches_tracked\n",
      "168 layer3.1.conv1.weight\n",
      "169 layer3.1.bn1.weight\n",
      "170 layer3.1.bn1.bias\n",
      "171 layer3.1.bn1.running_mean\n",
      "172 layer3.1.bn1.running_var\n",
      "173 layer3.1.bn1.num_batches_tracked\n",
      "174 layer3.1.conv2.weight\n",
      "175 layer3.1.bn2.weight\n",
      "176 layer3.1.bn2.bias\n",
      "177 layer3.1.bn2.running_mean\n",
      "178 layer3.1.bn2.running_var\n",
      "179 layer3.1.bn2.num_batches_tracked\n",
      "180 layer3.1.conv3.weight\n",
      "181 layer3.1.bn3.weight\n",
      "182 layer3.1.bn3.bias\n",
      "183 layer3.1.bn3.running_mean\n",
      "184 layer3.1.bn3.running_var\n",
      "185 layer3.1.bn3.num_batches_tracked\n",
      "186 layer3.2.conv1.weight\n",
      "187 layer3.2.bn1.weight\n",
      "188 layer3.2.bn1.bias\n",
      "189 layer3.2.bn1.running_mean\n",
      "190 layer3.2.bn1.running_var\n",
      "191 layer3.2.bn1.num_batches_tracked\n",
      "192 layer3.2.conv2.weight\n",
      "193 layer3.2.bn2.weight\n",
      "194 layer3.2.bn2.bias\n",
      "195 layer3.2.bn2.running_mean\n",
      "196 layer3.2.bn2.running_var\n",
      "197 layer3.2.bn2.num_batches_tracked\n",
      "198 layer3.2.conv3.weight\n",
      "199 layer3.2.bn3.weight\n",
      "200 layer3.2.bn3.bias\n",
      "201 layer3.2.bn3.running_mean\n",
      "202 layer3.2.bn3.running_var\n",
      "203 layer3.2.bn3.num_batches_tracked\n",
      "204 layer3.3.conv1.weight\n",
      "205 layer3.3.bn1.weight\n",
      "206 layer3.3.bn1.bias\n",
      "207 layer3.3.bn1.running_mean\n",
      "208 layer3.3.bn1.running_var\n",
      "209 layer3.3.bn1.num_batches_tracked\n",
      "210 layer3.3.conv2.weight\n",
      "211 layer3.3.bn2.weight\n",
      "212 layer3.3.bn2.bias\n",
      "213 layer3.3.bn2.running_mean\n",
      "214 layer3.3.bn2.running_var\n",
      "215 layer3.3.bn2.num_batches_tracked\n",
      "216 layer3.3.conv3.weight\n",
      "217 layer3.3.bn3.weight\n",
      "218 layer3.3.bn3.bias\n",
      "219 layer3.3.bn3.running_mean\n",
      "220 layer3.3.bn3.running_var\n",
      "221 layer3.3.bn3.num_batches_tracked\n",
      "222 layer3.4.conv1.weight\n",
      "223 layer3.4.bn1.weight\n",
      "224 layer3.4.bn1.bias\n",
      "225 layer3.4.bn1.running_mean\n",
      "226 layer3.4.bn1.running_var\n",
      "227 layer3.4.bn1.num_batches_tracked\n",
      "228 layer3.4.conv2.weight\n",
      "229 layer3.4.bn2.weight\n",
      "230 layer3.4.bn2.bias\n",
      "231 layer3.4.bn2.running_mean\n",
      "232 layer3.4.bn2.running_var\n",
      "233 layer3.4.bn2.num_batches_tracked\n",
      "234 layer3.4.conv3.weight\n",
      "235 layer3.4.bn3.weight\n",
      "236 layer3.4.bn3.bias\n",
      "237 layer3.4.bn3.running_mean\n",
      "238 layer3.4.bn3.running_var\n",
      "239 layer3.4.bn3.num_batches_tracked\n",
      "240 layer3.5.conv1.weight\n",
      "241 layer3.5.bn1.weight\n",
      "242 layer3.5.bn1.bias\n",
      "243 layer3.5.bn1.running_mean\n",
      "244 layer3.5.bn1.running_var\n",
      "245 layer3.5.bn1.num_batches_tracked\n",
      "246 layer3.5.conv2.weight\n",
      "247 layer3.5.bn2.weight\n",
      "248 layer3.5.bn2.bias\n",
      "249 layer3.5.bn2.running_mean\n",
      "250 layer3.5.bn2.running_var\n",
      "251 layer3.5.bn2.num_batches_tracked\n",
      "252 layer3.5.conv3.weight\n",
      "253 layer3.5.bn3.weight\n",
      "254 layer3.5.bn3.bias\n",
      "255 layer3.5.bn3.running_mean\n",
      "256 layer3.5.bn3.running_var\n",
      "257 layer3.5.bn3.num_batches_tracked\n",
      "258 layer4.0.conv1.weight\n",
      "259 layer4.0.bn1.weight\n",
      "260 layer4.0.bn1.bias\n",
      "261 layer4.0.bn1.running_mean\n",
      "262 layer4.0.bn1.running_var\n",
      "263 layer4.0.bn1.num_batches_tracked\n",
      "264 layer4.0.conv2.weight\n",
      "265 layer4.0.bn2.weight\n",
      "266 layer4.0.bn2.bias\n",
      "267 layer4.0.bn2.running_mean\n",
      "268 layer4.0.bn2.running_var\n",
      "269 layer4.0.bn2.num_batches_tracked\n",
      "270 layer4.0.conv3.weight\n",
      "271 layer4.0.bn3.weight\n",
      "272 layer4.0.bn3.bias\n",
      "273 layer4.0.bn3.running_mean\n",
      "274 layer4.0.bn3.running_var\n",
      "275 layer4.0.bn3.num_batches_tracked\n",
      "276 layer4.0.downsample.0.weight\n",
      "277 layer4.0.downsample.1.weight\n",
      "278 layer4.0.downsample.1.bias\n",
      "279 layer4.0.downsample.1.running_mean\n",
      "280 layer4.0.downsample.1.running_var\n",
      "281 layer4.0.downsample.1.num_batches_tracked\n",
      "282 layer4.1.conv1.weight\n",
      "283 layer4.1.bn1.weight\n",
      "284 layer4.1.bn1.bias\n",
      "285 layer4.1.bn1.running_mean\n",
      "286 layer4.1.bn1.running_var\n",
      "287 layer4.1.bn1.num_batches_tracked\n",
      "288 layer4.1.conv2.weight\n",
      "289 layer4.1.bn2.weight\n",
      "290 layer4.1.bn2.bias\n",
      "291 layer4.1.bn2.running_mean\n",
      "292 layer4.1.bn2.running_var\n",
      "293 layer4.1.bn2.num_batches_tracked\n",
      "294 layer4.1.conv3.weight\n",
      "295 layer4.1.bn3.weight\n",
      "296 layer4.1.bn3.bias\n",
      "297 layer4.1.bn3.running_mean\n",
      "298 layer4.1.bn3.running_var\n",
      "299 layer4.1.bn3.num_batches_tracked\n",
      "300 layer4.2.conv1.weight\n",
      "301 layer4.2.bn1.weight\n",
      "302 layer4.2.bn1.bias\n",
      "303 layer4.2.bn1.running_mean\n",
      "304 layer4.2.bn1.running_var\n",
      "305 layer4.2.bn1.num_batches_tracked\n",
      "306 layer4.2.conv2.weight\n",
      "307 layer4.2.bn2.weight\n",
      "308 layer4.2.bn2.bias\n",
      "309 layer4.2.bn2.running_mean\n",
      "310 layer4.2.bn2.running_var\n",
      "311 layer4.2.bn2.num_batches_tracked\n",
      "312 layer4.2.conv3.weight\n",
      "313 layer4.2.bn3.weight\n",
      "314 layer4.2.bn3.bias\n",
      "315 layer4.2.bn3.running_mean\n",
      "316 layer4.2.bn3.running_var\n",
      "317 layer4.2.bn3.num_batches_tracked\n",
      "318 fc.weight\n",
      "319 fc.bias\n"
     ]
    }
   ],
   "source": [
    "#参数保存在有序的字典中，那么可以通过查找参数的名字对应的id值，进行冻结\n",
    "model_dict = model.state_dict()\n",
    "dict_name = list(model_dict)\n",
    "for i, p in enumerate(dict_name):\n",
    "    print(i, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fc = nn.Linear(2048,33)#只修改最后一层全连接模型，由于我们昆虫数据集只有33个分类\n",
    "\n",
    "\n",
    "#或者这种写法\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 33)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=2048, out_features=33, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)#查看模型是否被成果修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=2048, out_features=33, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#把模型指定在GPU上运行\n",
    "#model = model.to(DEVICE)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data0/zengpz'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取数据，并对数据进行归一化处理\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "picturepath = '/data0/zengpz/insect（我处理）'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insect（我处理）\n",
      "/data0/zengpz\n",
      "['/data0/zengpz/insect（我处理）/桑褐刺蛾', '/data0/zengpz/insect（我处理）/绿盲蝽', '/data0/zengpz/insect（我处理）/毛虫', '/data0/zengpz/insect（我处理）/稻蝗', '/data0/zengpz/insect（我处理）/黑绒金龟', '/data0/zengpz/insect（我处理）/红蜘蛛', '/data0/zengpz/insect（我处理）/棉铃虫', '/data0/zengpz/insect（我处理）/二斑叶螨', '/data0/zengpz/insect（我处理）/瓢虫', '/data0/zengpz/insect（我处理）/军配虫', '/data0/zengpz/insect（我处理）/糠片盾蚧', '/data0/zengpz/insect（我处理）/吊丝虫', '/data0/zengpz/insect（我处理）/桉蓑蛾', '/data0/zengpz/insect（我处理）/大蓑蛾', '/data0/zengpz/insect（我处理）/菊天牛', '/data0/zengpz/insect（我处理）/褐软蚧', '/data0/zengpz/insect（我处理）/短额负蝗', '/data0/zengpz/insect（我处理）/柑橘粉蚧', '/data0/zengpz/insect（我处理）/条华蜗牛', '/data0/zengpz/insect（我处理）/蚧壳虫', '/data0/zengpz/insect（我处理）/稻绿蝽', '/data0/zengpz/insect（我处理）/灰巴蜗牛', '/data0/zengpz/insect（我处理）/吹绵蚧', '/data0/zengpz/insect（我处理）/蛞蝓', '/data0/zengpz/insect（我处理）/蓟马', '/data0/zengpz/insect（我处理）/白粉虱', '/data0/zengpz/insect（我处理）/红脚绿金龟', '/data0/zengpz/insect（我处理）/菜粉蝶', '/data0/zengpz/insect（我处理）/红蜡蚧', '/data0/zengpz/insect（我处理）/埃及吹棉介壳虫', '/data0/zengpz/insect（我处理）/根结线虫', '/data0/zengpz/insect（我处理）/考氏白盾蚧', '/data0/zengpz/insect（我处理）/木虱']\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "print(os.path.basename(picturepath))\n",
    "print(os.path.dirname(picturepath))\n",
    "\n",
    "import glob\n",
    "\n",
    "print(glob.glob('/data0/zengpz/insect（我处理）/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "['桑褐刺蛾', '绿盲蝽', '毛虫', '稻蝗', '黑绒金龟', '红蜘蛛', '棉铃虫', '二斑叶螨', '瓢虫', '军配虫', '糠片盾蚧', '吊丝虫', '桉蓑蛾', '大蓑蛾', '菊天牛', '褐软蚧', '短额负蝗', '柑橘粉蚧', '条华蜗牛', '蚧壳虫', '稻绿蝽', '灰巴蜗牛', '吹绵蚧', '蛞蝓', '蓟马', '白粉虱', '红脚绿金龟', '菜粉蝶', '红蜡蚧', '埃及吹棉介壳虫', '根结线虫', '考氏白盾蚧', '木虱']\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "list_dir = [i for i in glob.glob('/data0/zengpz/insect（我处理）/*')]\n",
    "print(len(list_dir))\n",
    "#show其中一张图片的路径\n",
    "list_dir_ =[]\n",
    "for i in range(len(list_dir)):\n",
    "    list_dir_ .append(list_dir[i].split('/')[4])\n",
    "print(list_dir_)\n",
    "print(len(list_dir_))#可以看到一共33个类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "#files = sorted(glob.glob('/data0/zengpz/insect（我处理）/桑褐刺蛾/*.jpg'))\n",
    "\n",
    "files = sorted(glob.glob('/data0/zengpz/insect（我处理）/*/*.jpg'))\n",
    "\n",
    "#print(files[32])\n",
    "print(len(files))\n",
    "#print(files)\n",
    "#t = '/data0/zengpz/insect（我处理）/桑褐刺蛾/1.jpg'\n",
    "#t in files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972\n",
      "972\n",
      "                                insectdir insectlabel\n",
      "0    /data0/zengpz/insect（我处理）/二斑叶螨/1.jpg        二斑叶螨\n",
      "1   /data0/zengpz/insect（我处理）/二斑叶螨/13.jpg        二斑叶螨\n",
      "2  /data0/zengpz/insect（我处理）/二斑叶螨/133.jpg        二斑叶螨\n",
      "3   /data0/zengpz/insect（我处理）/二斑叶螨/14.jpg        二斑叶螨\n",
      "4   /data0/zengpz/insect（我处理）/二斑叶螨/15.jpg        二斑叶螨\n"
     ]
    }
   ],
   "source": [
    "#查看显示某一张图片\n",
    "from PIL import Image\n",
    "files = sorted(glob.glob('/data0/zengpz/insect（我处理）/*/*.jpg'))\n",
    "#im = Image.open(r'list_dir[0]/')\n",
    "#im.show()\n",
    "image_labels = []\n",
    "filespath =[]\n",
    "for file in files:  \n",
    "    image_labels.append(file.split('/')[4])\n",
    "    filespath.append(file)\n",
    "    \n",
    "print(len(filespath))#一共972张照片\n",
    "print(len(image_labels))\n",
    "\n",
    "#把路径和label存成dataframe的形式\n",
    "from pandas import Series,DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "df = DataFrame()\n",
    "df['insectdir'] = filespath\n",
    "df['insectlabel'] = image_labels\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "#保存成csv文件，便于之后使用\n",
    "#\n",
    "#df.to_csv('insect_dataread.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "#把数据随机按照比例1:10划分训练集和测试集\n",
    "test_index = range(0,972,9) \n",
    "train_index = []\n",
    "\n",
    "for i in range(0,972):\n",
    "    if i not in test_index:\n",
    "        train_index.append(i)\n",
    "\n",
    "train = df.iloc[train_index,:]\n",
    "test = df.iloc[test_index,:]\n",
    "\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "#保存train数据\n",
    "#train.to_csv('insect_train.csv')\n",
    "#test.to_csv('insect_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对原始图片的预处理\n",
    "from torchvision import transforms as transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n",
    "    transforms.RandomRotation((-45,45)), #随机旋转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.229, 0.224, 0.225)), #R,G,B每层的归一化用到的均值和方差\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "#定义一个数据集\n",
    "class myDataset(Dataset):\n",
    "    \"\"\" 数据集演示 \"\"\"\n",
    "    def __init__(self, csv_file):\n",
    "        \"\"\"实现初始化方法，在初始化的时候将数据读载入\"\"\"\n",
    "        self.df=pd.read_csv(csv_file)\n",
    "        self.tags = {\"埃及吹棉介壳虫\": 0,\n",
    "                \"桉蓑蛾\": 1,\n",
    "                \"白粉虱\": 2,\n",
    "                \"菜粉蝶\": 3,\n",
    "                \"吹绵蚧\": 4,\n",
    "                \"大蓑蛾\": 5,\n",
    "                \"稻蝗\": 6,\n",
    "                \"稻绿蝽\": 7,\n",
    "                \"吊丝虫\": 8,\n",
    "                '短额负蝗':9,\n",
    "                '二斑叶螨':10,\n",
    "                '柑橘粉蚧':11,\n",
    "                '根结线虫':12,\n",
    "                '褐软蚧':13,\n",
    "                '黑绒金龟':14,\n",
    "                '红脚绿金龟':15,\n",
    "                '红蜡蚧':16,\n",
    "                '红蜘蛛':17,\n",
    "                '灰巴蜗牛':18,\n",
    "                '蓟马':19,\n",
    "                '蚧壳虫':20,\n",
    "                '菊天牛':21,\n",
    "                '军配虫':22,\n",
    "                '糠片盾蚧':23,\n",
    "                '考氏白盾蚧':24,\n",
    "                '蛞蝓':25,\n",
    "                '绿盲蝽':26,\n",
    "                '毛虫':27,\n",
    "                '棉铃虫':28,\n",
    "                '木虱':29,\n",
    "                '瓢虫':30,\n",
    "                '桑褐刺蛾':31,\n",
    "                '条华蜗牛':32\n",
    "                }\n",
    "        \n",
    "    def __len__(self):\n",
    "        '''\n",
    "        返回df的长度\n",
    "        '''\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        根据 idx 返回一行数据\n",
    "        \n",
    "        '''\n",
    "        img = Image.open(self.df.iloc[idx].insectdir).convert('RGB')\n",
    "        label = self.df.iloc[idx].insectlabel\n",
    "        label = self.tags[label]\n",
    "        img_path = self.df.iloc[idx].insectdir\n",
    "        #把图片做归一化处理\n",
    "        img = transform(img)\n",
    "        return img,label,img_path\n",
    "\n",
    "#修改读取的文件的路径    \n",
    "#ds_demo= myDataset('insect_dataread.csv')\n",
    "train_data =  myDataset('insect_train.csv')\n",
    "test_data = myDataset('insect_test.csv')\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.8786, -0.8272, -0.8101,  ..., -0.2621, -0.2450, -0.2108],\n",
       "          [-0.8615, -0.8444, -0.8272,  ..., -0.2279, -0.2108, -0.1765],\n",
       "          [-0.8615, -0.8444, -0.8272,  ..., -0.1936, -0.1594, -0.1423],\n",
       "          ...,\n",
       "          [ 0.2516, -0.1936, -0.6902,  ..., -0.5875, -0.6046, -0.7074],\n",
       "          [ 0.1489, -0.3135, -0.6046,  ..., -0.5190, -0.5875, -0.7416],\n",
       "          [ 0.0290, -0.3649, -0.4676,  ..., -0.4334, -0.5361, -0.7416]],\n",
       " \n",
       "         [[-0.4720, -0.4545, -0.4545,  ...,  0.1582,  0.1933,  0.2108],\n",
       "          [-0.4895, -0.4720, -0.4720,  ...,  0.1933,  0.2283,  0.2458],\n",
       "          [-0.4895, -0.4720, -0.4720,  ...,  0.2283,  0.2458,  0.2808],\n",
       "          ...,\n",
       "          [ 0.7360,  0.2633, -0.2444,  ..., -0.2794, -0.3144, -0.4195],\n",
       "          [ 0.6484,  0.1582, -0.1569,  ..., -0.2269, -0.2969, -0.4545],\n",
       "          [ 0.5084,  0.0882, -0.0168,  ..., -0.1569, -0.2444, -0.4545]],\n",
       " \n",
       "         [[-1.2524, -1.2524, -1.2524,  ..., -0.4681, -0.3810, -0.3287],\n",
       "          [-1.2524, -1.2698, -1.2698,  ..., -0.4158, -0.3287, -0.2764],\n",
       "          [-1.2524, -1.2698, -1.2698,  ..., -0.3635, -0.2938, -0.2415],\n",
       "          ...,\n",
       "          [ 0.2116, -0.2241, -0.6598,  ..., -0.8341, -0.7644, -0.8167],\n",
       "          [ 0.1245, -0.3461, -0.5727,  ..., -0.7295, -0.7121, -0.8341],\n",
       "          [-0.0149, -0.3984, -0.4332,  ..., -0.5901, -0.6598, -0.8515]]]),\n",
       " 10,\n",
       " '/data0/zengpz/insect（我处理）/二斑叶螨/133.jpg')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1]#用索引可以直接访问对应的数据, 对应 __getitem__ 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1][0].shape  #可以看到输入的图片已经做了归一化处理了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#测试一下是否真的有33类数据来训练\\nlist_ = []\\nfor i in range(0,864):\\n    list_.append(train_data[i][1])\\n    if train_data[i][1] < 0 or train_data[i][1] > 32:\\n        print(test_data[i][2])\\nprint(len(set(list_)))\\nset(list_)\\n'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#测试一下是否真的有33类数据来训练\n",
    "list_ = []\n",
    "for i in range(0,864):\n",
    "    list_.append(train_data[i][1])\n",
    "    if train_data[i][1] < 0 or train_data[i][1] > 32:\n",
    "        print(test_data[i][2])\n",
    "print(len(set(list_)))\n",
    "set(list_)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#使用官方提供的数据载入器，读取数据\n",
    "#常用参数有：batch_size(每个batch的大小), shuffle(是否进行shuffle操作), num_workers(加载数据的时候使用几个子进程)\n",
    "train_ = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True, num_workers=0)\n",
    "test_ = torch.utils.data.DataLoader(test_data, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "#DataLoader返回的是一个可迭代对象，我们可以使用迭代器分次获取数据\n",
    "#idata=iter(train)\n",
    "#print(next(idata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#冻结网络部分参数\n",
    "'''\n",
    "for i,p in enumerate(model.parameters()):\n",
    "    if i < 200:\n",
    "        p.requires_grad = False\n",
    "'''\n",
    "#loss function and optimizer\n",
    "criterion=torch.nn.CrossEntropyLoss()\n",
    "#parameters only train the last fc layer\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "#optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "#optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def trainmodel(model,train_loader,optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (inputs_, labels_, _) in enumerate(train_loader):\n",
    "    #for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        #inputs = inputs.to(device)#用GPU训练\n",
    "        #labels = labels.to(device)\n",
    "        \n",
    "        \n",
    "        cuda = torch.device('cuda') \n",
    "        #直接用torch.tensor会有warning\n",
    "        inputs = torch.tensor(inputs_).cuda()\n",
    "        labels = torch.tensor(labels_).cuda()\n",
    "        #inputs = inputs_.clone().detach().requires_grad_(True)\n",
    "        #labels = labels_.clone().detach()\n",
    "        \n",
    "        \n",
    "        #inputs = inputs.to(device)#用GPU训练\n",
    "        #labels = labels.to(device)\n",
    "        #inputs = inputs.cpu()\n",
    "        #labels = labels.cpu()\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        \n",
    "        #loss = F.nll_loss(output, target)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch_idx+1)%30 == 0: \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(inputs_), len(train_loader)*len(inputs_),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "accuracy = []\n",
    "def testmodel(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels, _) in enumerate(test_loader):\n",
    "            \n",
    "            cuda = torch.device('cuda') \n",
    "            #这样有warning\n",
    "            data = torch.tensor(inputs).cuda()\n",
    "            target = torch.tensor(labels).cuda()\n",
    "            #data = inputs.clone().detach().requires_grad_(True)\n",
    "            #target = labels.clone().detach\n",
    "            \n",
    "            \n",
    "            #device = torch.device(\"cuda\")\n",
    "            #data, target = data.to(device), target.to(device)\n",
    "            #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            #data, target = data.cpu(), target.cpu()\n",
    "            \n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() # 将一批的损失相加\n",
    "            pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    accuracy.append(100. * correct / (len(inputs)*len(test_loader)))\n",
    "    if 100. * correct / (len(inputs)*len(test_loader)) >= max(accuracy):\n",
    "        torch.save(model.state_dict,'resnet50_insect_own_parameters.pkl')\n",
    "    test_loss /= len(inputs)*len(test_loader)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(inputs)*len(test_loader),\n",
    "        100. * correct / (len(inputs)*len(test_loader))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [232/864 (27%)]\tLoss: 2.955364\n",
      "Train Epoch: 1 [472/864 (55%)]\tLoss: 2.687227\n",
      "Train Epoch: 1 [712/864 (82%)]\tLoss: 2.690779\n",
      "\n",
      "Test set: Average loss: 0.8658, Accuracy: 17/56 (30%)\n",
      "\n",
      "Train Epoch: 2 [232/864 (27%)]\tLoss: 3.211566\n",
      "Train Epoch: 2 [472/864 (55%)]\tLoss: 2.780124\n",
      "Train Epoch: 2 [712/864 (82%)]\tLoss: 2.807317\n",
      "\n",
      "Test set: Average loss: 0.7664, Accuracy: 18/56 (32%)\n",
      "\n",
      "Train Epoch: 3 [232/864 (27%)]\tLoss: 3.268354\n",
      "Train Epoch: 3 [472/864 (55%)]\tLoss: 3.266315\n",
      "Train Epoch: 3 [712/864 (82%)]\tLoss: 3.180798\n",
      "\n",
      "Test set: Average loss: 0.8054, Accuracy: 17/56 (30%)\n",
      "\n",
      "Train Epoch: 4 [232/864 (27%)]\tLoss: 3.622007\n",
      "Train Epoch: 4 [472/864 (55%)]\tLoss: 3.511032\n",
      "Train Epoch: 4 [712/864 (82%)]\tLoss: 2.938801\n",
      "\n",
      "Test set: Average loss: 0.7595, Accuracy: 21/56 (38%)\n",
      "\n",
      "Train Epoch: 5 [232/864 (27%)]\tLoss: 3.650795\n",
      "Train Epoch: 5 [472/864 (55%)]\tLoss: 2.410575\n",
      "Train Epoch: 5 [712/864 (82%)]\tLoss: 2.633882\n",
      "\n",
      "Test set: Average loss: 0.7615, Accuracy: 20/56 (36%)\n",
      "\n",
      "Train Epoch: 6 [232/864 (27%)]\tLoss: 3.252092\n",
      "Train Epoch: 6 [472/864 (55%)]\tLoss: 2.792138\n",
      "Train Epoch: 6 [712/864 (82%)]\tLoss: 2.961748\n",
      "\n",
      "Test set: Average loss: 0.7366, Accuracy: 24/56 (43%)\n",
      "\n",
      "Train Epoch: 7 [232/864 (27%)]\tLoss: 3.152122\n",
      "Train Epoch: 7 [472/864 (55%)]\tLoss: 3.037395\n",
      "Train Epoch: 7 [712/864 (82%)]\tLoss: 2.241545\n",
      "\n",
      "Test set: Average loss: 0.7187, Accuracy: 30/56 (54%)\n",
      "\n",
      "Train Epoch: 8 [232/864 (27%)]\tLoss: 2.972595\n",
      "Train Epoch: 8 [472/864 (55%)]\tLoss: 3.096513\n",
      "Train Epoch: 8 [712/864 (82%)]\tLoss: 2.720046\n",
      "\n",
      "Test set: Average loss: 0.7260, Accuracy: 28/56 (50%)\n",
      "\n",
      "Train Epoch: 9 [232/864 (27%)]\tLoss: 2.516825\n",
      "Train Epoch: 9 [472/864 (55%)]\tLoss: 2.625243\n",
      "Train Epoch: 9 [712/864 (82%)]\tLoss: 2.732597\n",
      "\n",
      "Test set: Average loss: 0.7254, Accuracy: 24/56 (43%)\n",
      "\n",
      "Train Epoch: 10 [232/864 (27%)]\tLoss: 2.956813\n",
      "Train Epoch: 10 [472/864 (55%)]\tLoss: 2.894571\n",
      "Train Epoch: 10 [712/864 (82%)]\tLoss: 2.646970\n",
      "\n",
      "Test set: Average loss: 0.7324, Accuracy: 24/56 (43%)\n",
      "\n",
      "Train Epoch: 11 [232/864 (27%)]\tLoss: 3.036558\n",
      "Train Epoch: 11 [472/864 (55%)]\tLoss: 2.878906\n",
      "Train Epoch: 11 [712/864 (82%)]\tLoss: 2.877345\n",
      "\n",
      "Test set: Average loss: 0.7520, Accuracy: 26/56 (46%)\n",
      "\n",
      "Train Epoch: 12 [232/864 (27%)]\tLoss: 2.769499\n",
      "Train Epoch: 12 [472/864 (55%)]\tLoss: 3.859738\n",
      "Train Epoch: 12 [712/864 (82%)]\tLoss: 3.199769\n",
      "\n",
      "Test set: Average loss: 0.7293, Accuracy: 26/56 (46%)\n",
      "\n",
      "Train Epoch: 13 [232/864 (27%)]\tLoss: 2.325553\n",
      "Train Epoch: 13 [472/864 (55%)]\tLoss: 2.645907\n",
      "Train Epoch: 13 [712/864 (82%)]\tLoss: 2.727213\n",
      "\n",
      "Test set: Average loss: 0.7097, Accuracy: 27/56 (48%)\n",
      "\n",
      "Train Epoch: 14 [232/864 (27%)]\tLoss: 2.671171\n",
      "Train Epoch: 14 [472/864 (55%)]\tLoss: 2.357831\n",
      "Train Epoch: 14 [712/864 (82%)]\tLoss: 3.417245\n",
      "\n",
      "Test set: Average loss: 0.6988, Accuracy: 21/56 (38%)\n",
      "\n",
      "Train Epoch: 15 [232/864 (27%)]\tLoss: 2.622732\n",
      "Train Epoch: 15 [472/864 (55%)]\tLoss: 3.229228\n",
      "Train Epoch: 15 [712/864 (82%)]\tLoss: 2.653935\n",
      "\n",
      "Test set: Average loss: 0.7053, Accuracy: 23/56 (41%)\n",
      "\n",
      "Train Epoch: 16 [232/864 (27%)]\tLoss: 3.351654\n",
      "Train Epoch: 16 [472/864 (55%)]\tLoss: 2.636760\n",
      "Train Epoch: 16 [712/864 (82%)]\tLoss: 3.322844\n",
      "\n",
      "Test set: Average loss: 0.7064, Accuracy: 26/56 (46%)\n",
      "\n",
      "Train Epoch: 17 [232/864 (27%)]\tLoss: 2.920797\n",
      "Train Epoch: 17 [472/864 (55%)]\tLoss: 2.458960\n",
      "Train Epoch: 17 [712/864 (82%)]\tLoss: 3.208988\n",
      "\n",
      "Test set: Average loss: 0.6809, Accuracy: 29/56 (52%)\n",
      "\n",
      "Train Epoch: 18 [232/864 (27%)]\tLoss: 3.116881\n",
      "Train Epoch: 18 [472/864 (55%)]\tLoss: 2.241661\n",
      "Train Epoch: 18 [712/864 (82%)]\tLoss: 3.571489\n",
      "\n",
      "Test set: Average loss: 0.9865, Accuracy: 23/56 (41%)\n",
      "\n",
      "Train Epoch: 19 [232/864 (27%)]\tLoss: 2.018800\n",
      "Train Epoch: 19 [472/864 (55%)]\tLoss: 3.053984\n",
      "Train Epoch: 19 [712/864 (82%)]\tLoss: 3.320351\n",
      "\n",
      "Test set: Average loss: 0.6462, Accuracy: 32/56 (57%)\n",
      "\n",
      "Train Epoch: 20 [232/864 (27%)]\tLoss: 2.030199\n",
      "Train Epoch: 20 [472/864 (55%)]\tLoss: 1.948129\n",
      "Train Epoch: 20 [712/864 (82%)]\tLoss: 2.917004\n",
      "\n",
      "Test set: Average loss: 0.6172, Accuracy: 34/56 (61%)\n",
      "\n",
      "Train Epoch: 21 [232/864 (27%)]\tLoss: 2.667618\n",
      "Train Epoch: 21 [472/864 (55%)]\tLoss: 2.632059\n",
      "Train Epoch: 21 [712/864 (82%)]\tLoss: 2.534536\n",
      "\n",
      "Test set: Average loss: 0.6541, Accuracy: 33/56 (59%)\n",
      "\n",
      "Train Epoch: 22 [232/864 (27%)]\tLoss: 2.199932\n",
      "Train Epoch: 22 [472/864 (55%)]\tLoss: 2.487875\n",
      "Train Epoch: 22 [712/864 (82%)]\tLoss: 3.138013\n",
      "\n",
      "Test set: Average loss: 0.6194, Accuracy: 36/56 (64%)\n",
      "\n",
      "Train Epoch: 23 [232/864 (27%)]\tLoss: 3.226530\n",
      "Train Epoch: 23 [472/864 (55%)]\tLoss: 2.544060\n",
      "Train Epoch: 23 [712/864 (82%)]\tLoss: 2.450284\n",
      "\n",
      "Test set: Average loss: 0.6668, Accuracy: 34/56 (61%)\n",
      "\n",
      "Train Epoch: 24 [232/864 (27%)]\tLoss: 2.182229\n",
      "Train Epoch: 24 [472/864 (55%)]\tLoss: 3.106467\n",
      "Train Epoch: 24 [712/864 (82%)]\tLoss: 3.416203\n",
      "\n",
      "Test set: Average loss: 0.6210, Accuracy: 30/56 (54%)\n",
      "\n",
      "Train Epoch: 25 [232/864 (27%)]\tLoss: 2.472840\n",
      "Train Epoch: 25 [472/864 (55%)]\tLoss: 2.964581\n",
      "Train Epoch: 25 [712/864 (82%)]\tLoss: 2.516384\n",
      "\n",
      "Test set: Average loss: 0.6366, Accuracy: 37/56 (66%)\n",
      "\n",
      "Train Epoch: 26 [232/864 (27%)]\tLoss: 2.367126\n",
      "Train Epoch: 26 [472/864 (55%)]\tLoss: 1.942174\n",
      "Train Epoch: 26 [712/864 (82%)]\tLoss: 3.318306\n",
      "\n",
      "Test set: Average loss: 0.6211, Accuracy: 39/56 (70%)\n",
      "\n",
      "Train Epoch: 27 [232/864 (27%)]\tLoss: 2.464621\n",
      "Train Epoch: 27 [472/864 (55%)]\tLoss: 2.710496\n",
      "Train Epoch: 27 [712/864 (82%)]\tLoss: 2.095587\n",
      "\n",
      "Test set: Average loss: 0.7196, Accuracy: 35/56 (62%)\n",
      "\n",
      "Train Epoch: 28 [232/864 (27%)]\tLoss: 1.707167\n",
      "Train Epoch: 28 [472/864 (55%)]\tLoss: 1.908291\n",
      "Train Epoch: 28 [712/864 (82%)]\tLoss: 2.732259\n",
      "\n",
      "Test set: Average loss: 0.6148, Accuracy: 38/56 (68%)\n",
      "\n",
      "Train Epoch: 29 [232/864 (27%)]\tLoss: 2.630837\n",
      "Train Epoch: 29 [472/864 (55%)]\tLoss: 2.377614\n",
      "Train Epoch: 29 [712/864 (82%)]\tLoss: 2.883413\n",
      "\n",
      "Test set: Average loss: 0.6252, Accuracy: 33/56 (59%)\n",
      "\n",
      "Train Epoch: 30 [232/864 (27%)]\tLoss: 2.509349\n",
      "Train Epoch: 30 [472/864 (55%)]\tLoss: 1.748085\n",
      "Train Epoch: 30 [712/864 (82%)]\tLoss: 1.512181\n",
      "\n",
      "Test set: Average loss: 0.6207, Accuracy: 36/56 (64%)\n",
      "\n",
      "Train Epoch: 31 [232/864 (27%)]\tLoss: 3.436474\n",
      "Train Epoch: 31 [472/864 (55%)]\tLoss: 1.864592\n",
      "Train Epoch: 31 [712/864 (82%)]\tLoss: 2.251056\n",
      "\n",
      "Test set: Average loss: 0.6394, Accuracy: 35/56 (62%)\n",
      "\n",
      "Train Epoch: 32 [232/864 (27%)]\tLoss: 1.931963\n",
      "Train Epoch: 32 [472/864 (55%)]\tLoss: 2.005175\n",
      "Train Epoch: 32 [712/864 (82%)]\tLoss: 2.391496\n",
      "\n",
      "Test set: Average loss: 0.6587, Accuracy: 34/56 (61%)\n",
      "\n",
      "Train Epoch: 33 [232/864 (27%)]\tLoss: 1.877092\n",
      "Train Epoch: 33 [472/864 (55%)]\tLoss: 1.727607\n",
      "Train Epoch: 33 [712/864 (82%)]\tLoss: 2.704231\n",
      "\n",
      "Test set: Average loss: 0.6550, Accuracy: 35/56 (62%)\n",
      "\n",
      "Train Epoch: 34 [232/864 (27%)]\tLoss: 1.308999\n",
      "Train Epoch: 34 [472/864 (55%)]\tLoss: 2.150017\n",
      "Train Epoch: 34 [712/864 (82%)]\tLoss: 2.267422\n",
      "\n",
      "Test set: Average loss: 0.5910, Accuracy: 39/56 (70%)\n",
      "\n",
      "Train Epoch: 35 [232/864 (27%)]\tLoss: 3.332575\n",
      "Train Epoch: 35 [472/864 (55%)]\tLoss: 2.444927\n",
      "Train Epoch: 35 [712/864 (82%)]\tLoss: 2.663765\n",
      "\n",
      "Test set: Average loss: 0.5970, Accuracy: 41/56 (73%)\n",
      "\n",
      "Train Epoch: 36 [232/864 (27%)]\tLoss: 1.947349\n",
      "Train Epoch: 36 [472/864 (55%)]\tLoss: 2.451292\n",
      "Train Epoch: 36 [712/864 (82%)]\tLoss: 1.883585\n",
      "\n",
      "Test set: Average loss: 0.6316, Accuracy: 42/56 (75%)\n",
      "\n",
      "Train Epoch: 37 [232/864 (27%)]\tLoss: 1.966530\n",
      "Train Epoch: 37 [472/864 (55%)]\tLoss: 2.570029\n",
      "Train Epoch: 37 [712/864 (82%)]\tLoss: 1.516485\n",
      "\n",
      "Test set: Average loss: 0.6176, Accuracy: 38/56 (68%)\n",
      "\n",
      "Train Epoch: 38 [232/864 (27%)]\tLoss: 2.011315\n",
      "Train Epoch: 38 [472/864 (55%)]\tLoss: 2.679045\n",
      "Train Epoch: 38 [712/864 (82%)]\tLoss: 2.995128\n",
      "\n",
      "Test set: Average loss: 0.5897, Accuracy: 39/56 (70%)\n",
      "\n",
      "Train Epoch: 39 [232/864 (27%)]\tLoss: 1.201062\n",
      "Train Epoch: 39 [472/864 (55%)]\tLoss: 1.299233\n",
      "Train Epoch: 39 [712/864 (82%)]\tLoss: 2.070230\n",
      "\n",
      "Test set: Average loss: 0.5884, Accuracy: 38/56 (68%)\n",
      "\n",
      "Train Epoch: 40 [232/864 (27%)]\tLoss: 3.090127\n",
      "Train Epoch: 40 [472/864 (55%)]\tLoss: 2.041379\n",
      "Train Epoch: 40 [712/864 (82%)]\tLoss: 2.289149\n",
      "\n",
      "Test set: Average loss: 0.5997, Accuracy: 37/56 (66%)\n",
      "\n",
      "Train Epoch: 41 [232/864 (27%)]\tLoss: 1.432978\n",
      "Train Epoch: 41 [472/864 (55%)]\tLoss: 1.368278\n",
      "Train Epoch: 41 [712/864 (82%)]\tLoss: 1.630984\n",
      "\n",
      "Test set: Average loss: 0.6009, Accuracy: 36/56 (64%)\n",
      "\n",
      "Train Epoch: 42 [232/864 (27%)]\tLoss: 1.816769\n",
      "Train Epoch: 42 [472/864 (55%)]\tLoss: 2.976425\n",
      "Train Epoch: 42 [712/864 (82%)]\tLoss: 2.035785\n",
      "\n",
      "Test set: Average loss: 0.6216, Accuracy: 42/56 (75%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 43 [232/864 (27%)]\tLoss: 2.019795\n",
      "Train Epoch: 43 [472/864 (55%)]\tLoss: 1.981731\n",
      "Train Epoch: 43 [712/864 (82%)]\tLoss: 1.889513\n",
      "\n",
      "Test set: Average loss: 0.5528, Accuracy: 40/56 (71%)\n",
      "\n",
      "Train Epoch: 44 [232/864 (27%)]\tLoss: 1.878235\n",
      "Train Epoch: 44 [472/864 (55%)]\tLoss: 1.606584\n",
      "Train Epoch: 44 [712/864 (82%)]\tLoss: 1.688964\n",
      "\n",
      "Test set: Average loss: 0.5995, Accuracy: 44/56 (79%)\n",
      "\n",
      "Train Epoch: 45 [232/864 (27%)]\tLoss: 1.346582\n",
      "Train Epoch: 45 [472/864 (55%)]\tLoss: 1.613145\n",
      "Train Epoch: 45 [712/864 (82%)]\tLoss: 2.225943\n",
      "\n",
      "Test set: Average loss: 0.6242, Accuracy: 38/56 (68%)\n",
      "\n",
      "Train Epoch: 46 [232/864 (27%)]\tLoss: 1.230472\n",
      "Train Epoch: 46 [472/864 (55%)]\tLoss: 1.236927\n",
      "Train Epoch: 46 [712/864 (82%)]\tLoss: 2.661185\n",
      "\n",
      "Test set: Average loss: 0.5929, Accuracy: 40/56 (71%)\n",
      "\n",
      "Train Epoch: 47 [232/864 (27%)]\tLoss: 2.033680\n",
      "Train Epoch: 47 [472/864 (55%)]\tLoss: 1.887269\n",
      "Train Epoch: 47 [712/864 (82%)]\tLoss: 1.920817\n",
      "\n",
      "Test set: Average loss: 0.6298, Accuracy: 40/56 (71%)\n",
      "\n",
      "Train Epoch: 48 [232/864 (27%)]\tLoss: 1.281762\n",
      "Train Epoch: 48 [472/864 (55%)]\tLoss: 1.416826\n",
      "Train Epoch: 48 [712/864 (82%)]\tLoss: 1.533809\n",
      "\n",
      "Test set: Average loss: 0.7411, Accuracy: 38/56 (68%)\n",
      "\n",
      "Train Epoch: 49 [232/864 (27%)]\tLoss: 1.142990\n",
      "Train Epoch: 49 [472/864 (55%)]\tLoss: 0.893944\n",
      "Train Epoch: 49 [712/864 (82%)]\tLoss: 1.462778\n",
      "\n",
      "Test set: Average loss: 0.6428, Accuracy: 43/56 (77%)\n",
      "\n",
      "Train Epoch: 50 [232/864 (27%)]\tLoss: 2.015681\n",
      "Train Epoch: 50 [472/864 (55%)]\tLoss: 1.290803\n",
      "Train Epoch: 50 [712/864 (82%)]\tLoss: 0.561875\n",
      "\n",
      "Test set: Average loss: 0.5575, Accuracy: 42/56 (75%)\n",
      "\n",
      "Train Epoch: 51 [232/864 (27%)]\tLoss: 1.943158\n",
      "Train Epoch: 51 [472/864 (55%)]\tLoss: 1.501445\n",
      "Train Epoch: 51 [712/864 (82%)]\tLoss: 1.007456\n",
      "\n",
      "Test set: Average loss: 0.5288, Accuracy: 50/56 (89%)\n",
      "\n",
      "Train Epoch: 52 [232/864 (27%)]\tLoss: 1.467767\n",
      "Train Epoch: 52 [472/864 (55%)]\tLoss: 1.622543\n",
      "Train Epoch: 52 [712/864 (82%)]\tLoss: 1.119909\n",
      "\n",
      "Test set: Average loss: 0.5327, Accuracy: 46/56 (82%)\n",
      "\n",
      "Train Epoch: 53 [232/864 (27%)]\tLoss: 1.191232\n",
      "Train Epoch: 53 [472/864 (55%)]\tLoss: 1.106725\n",
      "Train Epoch: 53 [712/864 (82%)]\tLoss: 0.929304\n",
      "\n",
      "Test set: Average loss: 0.5899, Accuracy: 43/56 (77%)\n",
      "\n",
      "Train Epoch: 54 [232/864 (27%)]\tLoss: 1.486264\n",
      "Train Epoch: 54 [472/864 (55%)]\tLoss: 1.393566\n",
      "Train Epoch: 54 [712/864 (82%)]\tLoss: 1.727956\n",
      "\n",
      "Test set: Average loss: 0.6210, Accuracy: 49/56 (88%)\n",
      "\n",
      "Train Epoch: 55 [232/864 (27%)]\tLoss: 0.906908\n",
      "Train Epoch: 55 [472/864 (55%)]\tLoss: 1.598917\n",
      "Train Epoch: 55 [712/864 (82%)]\tLoss: 1.444501\n",
      "\n",
      "Test set: Average loss: 0.6085, Accuracy: 37/56 (66%)\n",
      "\n",
      "Train Epoch: 56 [232/864 (27%)]\tLoss: 1.923234\n",
      "Train Epoch: 56 [472/864 (55%)]\tLoss: 1.633729\n",
      "Train Epoch: 56 [712/864 (82%)]\tLoss: 1.104429\n",
      "\n",
      "Test set: Average loss: 0.5821, Accuracy: 45/56 (80%)\n",
      "\n",
      "Train Epoch: 57 [232/864 (27%)]\tLoss: 1.449718\n",
      "Train Epoch: 57 [472/864 (55%)]\tLoss: 0.889912\n",
      "Train Epoch: 57 [712/864 (82%)]\tLoss: 1.542437\n",
      "\n",
      "Test set: Average loss: 0.6819, Accuracy: 32/56 (57%)\n",
      "\n",
      "Train Epoch: 58 [232/864 (27%)]\tLoss: 1.099038\n",
      "Train Epoch: 58 [472/864 (55%)]\tLoss: 0.616483\n",
      "Train Epoch: 58 [712/864 (82%)]\tLoss: 1.395223\n",
      "\n",
      "Test set: Average loss: 0.5931, Accuracy: 40/56 (71%)\n",
      "\n",
      "Train Epoch: 59 [232/864 (27%)]\tLoss: 1.655361\n",
      "Train Epoch: 59 [472/864 (55%)]\tLoss: 1.733436\n",
      "Train Epoch: 59 [712/864 (82%)]\tLoss: 1.863582\n",
      "\n",
      "Test set: Average loss: 0.5892, Accuracy: 41/56 (73%)\n",
      "\n",
      "Train Epoch: 60 [232/864 (27%)]\tLoss: 1.116960\n",
      "Train Epoch: 60 [472/864 (55%)]\tLoss: 1.554437\n",
      "Train Epoch: 60 [712/864 (82%)]\tLoss: 1.281544\n",
      "\n",
      "Test set: Average loss: 0.6445, Accuracy: 42/56 (75%)\n",
      "\n",
      "Train Epoch: 61 [232/864 (27%)]\tLoss: 0.804151\n",
      "Train Epoch: 61 [472/864 (55%)]\tLoss: 2.045120\n",
      "Train Epoch: 61 [712/864 (82%)]\tLoss: 1.094737\n",
      "\n",
      "Test set: Average loss: 0.6452, Accuracy: 40/56 (71%)\n",
      "\n",
      "Train Epoch: 62 [232/864 (27%)]\tLoss: 0.892057\n",
      "Train Epoch: 62 [472/864 (55%)]\tLoss: 1.210290\n",
      "Train Epoch: 62 [712/864 (82%)]\tLoss: 0.569202\n",
      "\n",
      "Test set: Average loss: 0.5897, Accuracy: 46/56 (82%)\n",
      "\n",
      "Train Epoch: 63 [232/864 (27%)]\tLoss: 2.733966\n",
      "Train Epoch: 63 [472/864 (55%)]\tLoss: 1.190183\n",
      "Train Epoch: 63 [712/864 (82%)]\tLoss: 1.674006\n",
      "\n",
      "Test set: Average loss: 0.5516, Accuracy: 46/56 (82%)\n",
      "\n",
      "Train Epoch: 64 [232/864 (27%)]\tLoss: 1.084022\n",
      "Train Epoch: 64 [472/864 (55%)]\tLoss: 0.731048\n",
      "Train Epoch: 64 [712/864 (82%)]\tLoss: 1.323198\n",
      "\n",
      "Test set: Average loss: 0.6218, Accuracy: 39/56 (70%)\n",
      "\n",
      "Train Epoch: 65 [232/864 (27%)]\tLoss: 0.650346\n",
      "Train Epoch: 65 [472/864 (55%)]\tLoss: 1.152117\n",
      "Train Epoch: 65 [712/864 (82%)]\tLoss: 0.989288\n",
      "\n",
      "Test set: Average loss: 0.6303, Accuracy: 43/56 (77%)\n",
      "\n",
      "Train Epoch: 66 [232/864 (27%)]\tLoss: 1.076761\n",
      "Train Epoch: 66 [472/864 (55%)]\tLoss: 1.133643\n",
      "Train Epoch: 66 [712/864 (82%)]\tLoss: 0.993042\n",
      "\n",
      "Test set: Average loss: 0.5496, Accuracy: 51/56 (91%)\n",
      "\n",
      "Train Epoch: 67 [232/864 (27%)]\tLoss: 1.560555\n",
      "Train Epoch: 67 [472/864 (55%)]\tLoss: 2.014449\n",
      "Train Epoch: 67 [712/864 (82%)]\tLoss: 0.917119\n",
      "\n",
      "Test set: Average loss: 0.6014, Accuracy: 45/56 (80%)\n",
      "\n",
      "Train Epoch: 68 [232/864 (27%)]\tLoss: 0.654288\n",
      "Train Epoch: 68 [472/864 (55%)]\tLoss: 0.509433\n",
      "Train Epoch: 68 [712/864 (82%)]\tLoss: 1.690803\n",
      "\n",
      "Test set: Average loss: 0.8128, Accuracy: 39/56 (70%)\n",
      "\n",
      "Train Epoch: 69 [232/864 (27%)]\tLoss: 0.432078\n",
      "Train Epoch: 69 [472/864 (55%)]\tLoss: 0.584775\n",
      "Train Epoch: 69 [712/864 (82%)]\tLoss: 1.879229\n",
      "\n",
      "Test set: Average loss: 0.5664, Accuracy: 47/56 (84%)\n",
      "\n",
      "Train Epoch: 70 [232/864 (27%)]\tLoss: 1.232752\n",
      "Train Epoch: 70 [472/864 (55%)]\tLoss: 1.289856\n",
      "Train Epoch: 70 [712/864 (82%)]\tLoss: 0.505364\n",
      "\n",
      "Test set: Average loss: 0.6107, Accuracy: 38/56 (68%)\n",
      "\n",
      "Train Epoch: 71 [232/864 (27%)]\tLoss: 2.001017\n",
      "Train Epoch: 71 [472/864 (55%)]\tLoss: 0.856209\n",
      "Train Epoch: 71 [712/864 (82%)]\tLoss: 0.619641\n",
      "\n",
      "Test set: Average loss: 0.6248, Accuracy: 43/56 (77%)\n",
      "\n",
      "Train Epoch: 72 [232/864 (27%)]\tLoss: 1.094051\n",
      "Train Epoch: 72 [472/864 (55%)]\tLoss: 1.073974\n",
      "Train Epoch: 72 [712/864 (82%)]\tLoss: 0.717719\n",
      "\n",
      "Test set: Average loss: 0.5765, Accuracy: 43/56 (77%)\n",
      "\n",
      "Train Epoch: 73 [232/864 (27%)]\tLoss: 1.114073\n",
      "Train Epoch: 73 [472/864 (55%)]\tLoss: 1.479357\n",
      "Train Epoch: 73 [712/864 (82%)]\tLoss: 0.796884\n",
      "\n",
      "Test set: Average loss: 0.6238, Accuracy: 50/56 (89%)\n",
      "\n",
      "Train Epoch: 74 [232/864 (27%)]\tLoss: 0.935090\n",
      "Train Epoch: 74 [472/864 (55%)]\tLoss: 0.233993\n",
      "Train Epoch: 74 [712/864 (82%)]\tLoss: 0.321977\n",
      "\n",
      "Test set: Average loss: 0.5898, Accuracy: 44/56 (79%)\n",
      "\n",
      "Train Epoch: 75 [232/864 (27%)]\tLoss: 0.439008\n",
      "Train Epoch: 75 [472/864 (55%)]\tLoss: 0.641257\n",
      "Train Epoch: 75 [712/864 (82%)]\tLoss: 1.189132\n",
      "\n",
      "Test set: Average loss: 0.6387, Accuracy: 39/56 (70%)\n",
      "\n",
      "Train Epoch: 76 [232/864 (27%)]\tLoss: 1.453625\n",
      "Train Epoch: 76 [472/864 (55%)]\tLoss: 1.030038\n",
      "Train Epoch: 76 [712/864 (82%)]\tLoss: 0.812077\n",
      "\n",
      "Test set: Average loss: 0.6583, Accuracy: 45/56 (80%)\n",
      "\n",
      "Train Epoch: 77 [232/864 (27%)]\tLoss: 0.766536\n",
      "Train Epoch: 77 [472/864 (55%)]\tLoss: 0.606225\n",
      "Train Epoch: 77 [712/864 (82%)]\tLoss: 0.628876\n",
      "\n",
      "Test set: Average loss: 0.6655, Accuracy: 40/56 (71%)\n",
      "\n",
      "Train Epoch: 78 [232/864 (27%)]\tLoss: 0.743213\n",
      "Train Epoch: 78 [472/864 (55%)]\tLoss: 0.839661\n",
      "Train Epoch: 78 [712/864 (82%)]\tLoss: 0.551313\n",
      "\n",
      "Test set: Average loss: 0.7026, Accuracy: 41/56 (73%)\n",
      "\n",
      "Train Epoch: 79 [232/864 (27%)]\tLoss: 0.572463\n",
      "Train Epoch: 79 [472/864 (55%)]\tLoss: 1.129074\n",
      "Train Epoch: 79 [712/864 (82%)]\tLoss: 0.490898\n",
      "\n",
      "Test set: Average loss: 0.7319, Accuracy: 45/56 (80%)\n",
      "\n",
      "Train Epoch: 80 [232/864 (27%)]\tLoss: 0.755520\n",
      "Train Epoch: 80 [472/864 (55%)]\tLoss: 0.710864\n",
      "Train Epoch: 80 [712/864 (82%)]\tLoss: 0.552957\n",
      "\n",
      "Test set: Average loss: 0.7208, Accuracy: 42/56 (75%)\n",
      "\n",
      "Train Epoch: 81 [232/864 (27%)]\tLoss: 0.302858\n",
      "Train Epoch: 81 [472/864 (55%)]\tLoss: 1.208763\n",
      "Train Epoch: 81 [712/864 (82%)]\tLoss: 1.123749\n",
      "\n",
      "Test set: Average loss: 0.6857, Accuracy: 38/56 (68%)\n",
      "\n",
      "Train Epoch: 82 [232/864 (27%)]\tLoss: 0.340551\n",
      "Train Epoch: 82 [472/864 (55%)]\tLoss: 1.096957\n",
      "Train Epoch: 82 [712/864 (82%)]\tLoss: 1.522523\n",
      "\n",
      "Test set: Average loss: 0.7943, Accuracy: 45/56 (80%)\n",
      "\n",
      "Train Epoch: 83 [232/864 (27%)]\tLoss: 0.719872\n",
      "Train Epoch: 83 [472/864 (55%)]\tLoss: 1.100120\n",
      "Train Epoch: 83 [712/864 (82%)]\tLoss: 1.461751\n",
      "\n",
      "Test set: Average loss: 0.6526, Accuracy: 39/56 (70%)\n",
      "\n",
      "Train Epoch: 84 [232/864 (27%)]\tLoss: 0.488393\n",
      "Train Epoch: 84 [472/864 (55%)]\tLoss: 1.179541\n",
      "Train Epoch: 84 [712/864 (82%)]\tLoss: 0.737887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6901, Accuracy: 48/56 (86%)\n",
      "\n",
      "Train Epoch: 85 [232/864 (27%)]\tLoss: 0.496396\n",
      "Train Epoch: 85 [472/864 (55%)]\tLoss: 0.427734\n",
      "Train Epoch: 85 [712/864 (82%)]\tLoss: 0.845199\n",
      "\n",
      "Test set: Average loss: 0.7080, Accuracy: 53/56 (95%)\n",
      "\n",
      "Train Epoch: 86 [232/864 (27%)]\tLoss: 0.717840\n",
      "Train Epoch: 86 [472/864 (55%)]\tLoss: 0.462662\n",
      "Train Epoch: 86 [712/864 (82%)]\tLoss: 0.704701\n",
      "\n",
      "Test set: Average loss: 0.7167, Accuracy: 46/56 (82%)\n",
      "\n",
      "Train Epoch: 87 [232/864 (27%)]\tLoss: 0.811616\n",
      "Train Epoch: 87 [472/864 (55%)]\tLoss: 0.615898\n",
      "Train Epoch: 87 [712/864 (82%)]\tLoss: 0.856615\n",
      "\n",
      "Test set: Average loss: 0.8081, Accuracy: 47/56 (84%)\n",
      "\n",
      "Train Epoch: 88 [232/864 (27%)]\tLoss: 1.045968\n",
      "Train Epoch: 88 [472/864 (55%)]\tLoss: 0.684165\n",
      "Train Epoch: 88 [712/864 (82%)]\tLoss: 0.496303\n",
      "\n",
      "Test set: Average loss: 0.6745, Accuracy: 44/56 (79%)\n",
      "\n",
      "Train Epoch: 89 [232/864 (27%)]\tLoss: 0.811421\n",
      "Train Epoch: 89 [472/864 (55%)]\tLoss: 0.528530\n",
      "Train Epoch: 89 [712/864 (82%)]\tLoss: 0.690618\n",
      "\n",
      "Test set: Average loss: 0.6508, Accuracy: 48/56 (86%)\n",
      "\n",
      "Train Epoch: 90 [232/864 (27%)]\tLoss: 1.116666\n",
      "Train Epoch: 90 [472/864 (55%)]\tLoss: 1.144064\n",
      "Train Epoch: 90 [712/864 (82%)]\tLoss: 0.290460\n",
      "\n",
      "Test set: Average loss: 0.7549, Accuracy: 49/56 (88%)\n",
      "\n",
      "Train Epoch: 91 [232/864 (27%)]\tLoss: 0.575126\n",
      "Train Epoch: 91 [472/864 (55%)]\tLoss: 0.411221\n",
      "Train Epoch: 91 [712/864 (82%)]\tLoss: 1.025270\n",
      "\n",
      "Test set: Average loss: 0.6969, Accuracy: 52/56 (93%)\n",
      "\n",
      "Train Epoch: 92 [232/864 (27%)]\tLoss: 0.383104\n",
      "Train Epoch: 92 [472/864 (55%)]\tLoss: 0.314109\n",
      "Train Epoch: 92 [712/864 (82%)]\tLoss: 0.471701\n",
      "\n",
      "Test set: Average loss: 0.8548, Accuracy: 42/56 (75%)\n",
      "\n",
      "Train Epoch: 93 [232/864 (27%)]\tLoss: 0.638531\n",
      "Train Epoch: 93 [472/864 (55%)]\tLoss: 0.416869\n",
      "Train Epoch: 93 [712/864 (82%)]\tLoss: 0.516216\n",
      "\n",
      "Test set: Average loss: 0.7416, Accuracy: 40/56 (71%)\n",
      "\n",
      "Train Epoch: 94 [232/864 (27%)]\tLoss: 0.807538\n",
      "Train Epoch: 94 [472/864 (55%)]\tLoss: 0.220672\n",
      "Train Epoch: 94 [712/864 (82%)]\tLoss: 0.561690\n",
      "\n",
      "Test set: Average loss: 0.7008, Accuracy: 42/56 (75%)\n",
      "\n",
      "Train Epoch: 95 [232/864 (27%)]\tLoss: 0.165015\n",
      "Train Epoch: 95 [472/864 (55%)]\tLoss: 0.424416\n",
      "Train Epoch: 95 [712/864 (82%)]\tLoss: 0.557040\n",
      "\n",
      "Test set: Average loss: 0.6777, Accuracy: 50/56 (89%)\n",
      "\n",
      "Train Epoch: 96 [232/864 (27%)]\tLoss: 0.571925\n",
      "Train Epoch: 96 [472/864 (55%)]\tLoss: 0.287470\n",
      "Train Epoch: 96 [712/864 (82%)]\tLoss: 0.561990\n",
      "\n",
      "Test set: Average loss: 0.8594, Accuracy: 44/56 (79%)\n",
      "\n",
      "Train Epoch: 97 [232/864 (27%)]\tLoss: 0.868584\n",
      "Train Epoch: 97 [472/864 (55%)]\tLoss: 0.488116\n",
      "Train Epoch: 97 [712/864 (82%)]\tLoss: 0.236362\n",
      "\n",
      "Test set: Average loss: 0.7975, Accuracy: 49/56 (88%)\n",
      "\n",
      "Train Epoch: 98 [232/864 (27%)]\tLoss: 0.389031\n",
      "Train Epoch: 98 [472/864 (55%)]\tLoss: 0.456316\n",
      "Train Epoch: 98 [712/864 (82%)]\tLoss: 0.474130\n",
      "\n",
      "Test set: Average loss: 0.7187, Accuracy: 47/56 (84%)\n",
      "\n",
      "Train Epoch: 99 [232/864 (27%)]\tLoss: 0.647011\n",
      "Train Epoch: 99 [472/864 (55%)]\tLoss: 0.920317\n",
      "Train Epoch: 99 [712/864 (82%)]\tLoss: 0.837854\n",
      "\n",
      "Test set: Average loss: 0.7343, Accuracy: 45/56 (80%)\n",
      "\n",
      "Train Epoch: 100 [232/864 (27%)]\tLoss: 0.221505\n",
      "Train Epoch: 100 [472/864 (55%)]\tLoss: 0.069395\n",
      "Train Epoch: 100 [712/864 (82%)]\tLoss: 0.389948\n",
      "\n",
      "Test set: Average loss: 0.6669, Accuracy: 50/56 (89%)\n",
      "\n",
      "最好的识别率： 94.64285714285714\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#开始训练过程\n",
    "EPOCHS = 100\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    trainmodel(model, train_, optimizer, epoch)\n",
    "    testmodel(model,test_)\n",
    "print('最好的识别率：',max(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'accuracy')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#画出准确率随着epoch的变化而变化的图\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(range(0,100),accuracy)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
